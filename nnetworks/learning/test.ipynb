{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "PROJECT_PATH = \"/home/albert/Baikal-ML/\" #insert your project path\n",
    "sys.path.append(f\"{PROJECT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 23:22:16,061 - INFO - Shuffled all file paths. Total paths: 106\n",
      "2024-11-03 23:22:16,062 - INFO - Shuffled all file paths. Total paths: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=6fcec5dafd0a42d09135b1fdf83b1e3e\n",
      "2024-11-03 23:22:21,281 - clearml.Task - INFO - Storing jupyter notebook directly as code\n",
      "ClearML results page: https://app.clear.ml/projects/34ab15018bbd432099027156dccd5717/experiments/6fcec5dafd0a42d09135b1fdf83b1e3e/output/log\n"
     ]
    }
   ],
   "source": [
    "from clearml import Task\n",
    "\n",
    "import data.config_manager as cfgm\n",
    "from data.batch_generator import BatchGenerator\n",
    "from nnetworks.models.config_manager import model_from_yaml\n",
    "from nnetworks.learning.config_manager import yaml2trainercfg\n",
    "from nnetworks.models.munusep_resnet import MuNuSepResNet\n",
    "from nnetworks.learning.trainers import MuNuSepTrainer\n",
    "from nnetworks.learning.config import TrainerConfig\n",
    "\n",
    "# data\n",
    "name_of_dataset = \"munusep_all_small\"\n",
    "train_paths = cfgm.read_paths(f\"/home/albert/Baikal-ML/data/configurations/{name_of_dataset}/train_paths.csv\")\n",
    "test_paths = cfgm.read_paths(f\"/home/albert/Baikal-ML/data/configurations/{name_of_dataset}/test_paths.csv\")\n",
    "cfg = cfgm.load_cfg(f\"/home/albert/Baikal-ML/data/configurations/{name_of_dataset}/cfg.yaml\")\n",
    "train_gen, test_gen = BatchGenerator(train_paths, cfg), BatchGenerator(test_paths, cfg)\n",
    "\n",
    "# model\n",
    "model = model_from_yaml(MuNuSepResNet, \"/home/albert/Baikal-ML/nnetworks/models/configurations/munusep_all_resnet.yaml\")\n",
    "\n",
    "\n",
    "project_name = \"MuNuSepAll\"\n",
    "task_name=\"03_11_24_ResNet_SmallDS_FirstTrial\"\n",
    "# ClearML\n",
    "task = Task.init(project_name, task_name) \n",
    "# trainer\n",
    "learning_cfg = yaml2trainercfg(\"/home/albert/Baikal-ML/nnetworks/learning/configurations/munusepall_short.yaml\")\n",
    "learning_cfg.experiment_path = f\"/home/albert/Baikal-ML/experiments/{project_name}/{task_name}\"\n",
    "fitter = MuNuSepTrainer(model, \n",
    "                        train_gen, \n",
    "                        test_gen=test_gen, \n",
    "                        train_config=learning_cfg,\n",
    "                        clearml_task=task)\n",
    "try:\n",
    "    fitter.train()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    task.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 18:17:58,801 - INFO - Shuffled all file paths. Total paths: 40\n",
      "2024-11-03 18:17:58,803 - INFO - Shuffled all file paths. Total paths: 10\n",
      "2024-11-03 18:18:00,208 - INFO - Initialized MuNuSepTrainer\n"
     ]
    }
   ],
   "source": [
    "import data.config_manager as cfgm\n",
    "from data.batch_generator import BatchGenerator\n",
    "from nnetworks.models.config_manager import model_from_yaml\n",
    "from nnetworks.models.munusep_resnet import MuNuSepResNet\n",
    "from nnetworks.learning.trainers import MuNuSepTrainer\n",
    "from nnetworks.learning.config import TrainerConfig\n",
    "\n",
    "# data\n",
    "name_of_dataset = \"numusep_signal_small\"\n",
    "train_paths = cfgm.read_paths(f\"/home/albert/Baikal-ML/data/configurations/{name_of_dataset}/train_paths.csv\")\n",
    "train_paths = train_paths[0:20] + train_paths[-20:]\n",
    "test_paths = cfgm.read_paths(f\"/home/albert/Baikal-ML/data/configurations/{name_of_dataset}/test_paths.csv\")\n",
    "test_paths = test_paths[0:5] + test_paths[-5:]\n",
    "cfg = cfgm.load_cfg(f\"/home/albert/Baikal-ML/data/configurations/{name_of_dataset}/cfg.yaml\")\n",
    "train_gen, test_gen = BatchGenerator(train_paths, cfg), BatchGenerator(test_paths, cfg)\n",
    "\n",
    "# model\n",
    "model = model_from_yaml(MuNuSepResNet, \"/home/albert/Baikal-ML/nnetworks/models/configurations/munusep_resnet.yaml\")\n",
    "\n",
    "# trainer\n",
    "fitter = MuNuSepTrainer(model, train_gen, test_gen, TrainerConfig())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 18:18:00,219 - INFO - \n",
      "Started Epoch 0/3\n",
      "2024-11-03 18:18:14,211 - INFO - #0 chunk loaded.\n",
      "2024-11-03 18:18:15,043 - INFO - logged Train Loss FocalLoss\n",
      "2024-11-03 18:18:15,050 - INFO - computed metrics\n",
      "2024-11-03 18:18:15,051 - INFO - logged Train Metrics Accuracy\n",
      "2024-11-03 18:18:15,052 - INFO - logged Train Metrics Precision\n",
      "2024-11-03 18:18:15,052 - INFO - logged Train Metrics TPR\n",
      "2024-11-03 18:18:15,053 - INFO - logged Train Metrics FPR\n",
      "2024-11-03 18:18:15,054 - INFO - logged Train Metrics AUC\n",
      "2024-11-03 18:18:21,297 - INFO - logged Train Loss FocalLoss\n",
      "2024-11-03 18:18:21,331 - INFO - computed metrics\n",
      "2024-11-03 18:18:21,332 - INFO - logged Train Metrics Accuracy\n",
      "2024-11-03 18:18:21,333 - INFO - logged Train Metrics Precision\n",
      "2024-11-03 18:18:21,334 - INFO - logged Train Metrics TPR\n",
      "2024-11-03 18:18:21,335 - INFO - logged Train Metrics FPR\n",
      "2024-11-03 18:18:21,336 - INFO - logged Train Metrics AUC\n",
      "2024-11-03 18:18:26,985 - INFO - logged Train Loss FocalLoss\n",
      "2024-11-03 18:18:27,040 - INFO - computed metrics\n",
      "2024-11-03 18:18:27,042 - INFO - logged Train Metrics Accuracy\n",
      "2024-11-03 18:18:27,043 - INFO - logged Train Metrics Precision\n",
      "2024-11-03 18:18:27,043 - INFO - logged Train Metrics TPR\n",
      "2024-11-03 18:18:27,045 - INFO - logged Train Metrics FPR\n",
      "2024-11-03 18:18:27,047 - INFO - logged Train Metrics AUC\n",
      "2024-11-03 18:18:32,334 - INFO - logged Train Loss FocalLoss\n",
      "2024-11-03 18:18:32,411 - INFO - computed metrics\n",
      "2024-11-03 18:18:32,412 - INFO - logged Train Metrics Accuracy\n",
      "2024-11-03 18:18:32,414 - INFO - logged Train Metrics Precision\n",
      "2024-11-03 18:18:32,415 - INFO - logged Train Metrics TPR\n",
      "2024-11-03 18:18:32,416 - INFO - logged Train Metrics FPR\n",
      "2024-11-03 18:18:32,416 - INFO - logged Train Metrics AUC\n",
      "2024-11-03 18:18:37,709 - INFO - logged Train Loss FocalLoss\n",
      "2024-11-03 18:18:37,811 - INFO - computed metrics\n",
      "2024-11-03 18:18:37,812 - INFO - logged Train Metrics Accuracy\n",
      "2024-11-03 18:18:37,813 - INFO - logged Train Metrics Precision\n",
      "2024-11-03 18:18:37,813 - INFO - logged Train Metrics TPR\n",
      "2024-11-03 18:18:37,814 - INFO - logged Train Metrics FPR\n",
      "2024-11-03 18:18:37,815 - INFO - logged Train Metrics AUC\n",
      "2024-11-03 18:18:43,369 - INFO - End of Epoch 0. Getting metrics.\n",
      "2024-11-03 18:18:43,502 - INFO - computed metrics\n",
      "2024-11-03 18:18:43,504 - INFO - logged Train Metrics Accuracy\n",
      "2024-11-03 18:18:43,505 - INFO - logged Train Metrics Precision\n",
      "2024-11-03 18:18:43,506 - INFO - logged Train Metrics TPR\n",
      "2024-11-03 18:18:43,508 - INFO - logged Train Metrics FPR\n",
      "2024-11-03 18:18:43,509 - INFO - logged Train Metrics AUC\n",
      "2024-11-03 18:18:43,512 - INFO - Starting evaluation on test dataset\n",
      "2024-11-03 18:18:49,349 - INFO - #0 chunk loaded.\n",
      "2024-11-03 18:19:10,067 - INFO - Shuffled all file paths. Total paths: 10\n",
      "2024-11-03 18:19:10,199 - INFO - computed metrics\n",
      "2024-11-03 18:19:10,201 - INFO - logged Test Metrics Accuracy\n",
      "2024-11-03 18:19:10,202 - INFO - logged Test Metrics Precision\n",
      "2024-11-03 18:19:10,203 - INFO - logged Test Metrics TPR\n",
      "2024-11-03 18:19:10,205 - INFO - logged Test Metrics FPR\n",
      "2024-11-03 18:19:10,206 - INFO - logged Test Metrics AUC\n",
      "2024-11-03 18:19:10,227 - INFO - Saved checkpoint for Epoch 0\n",
      "2024-11-03 18:19:10,228 - INFO - \n",
      "Started Epoch 1/3\n",
      "2024-11-03 18:19:10,285 - INFO - logged Train Loss FocalLoss\n",
      "2024-11-03 18:19:10,294 - INFO - computed metrics\n",
      "2024-11-03 18:19:10,295 - INFO - logged Train Metrics Accuracy\n",
      "2024-11-03 18:19:10,297 - INFO - logged Train Metrics Precision\n",
      "2024-11-03 18:19:10,298 - INFO - logged Train Metrics TPR\n",
      "2024-11-03 18:19:10,299 - INFO - logged Train Metrics FPR\n",
      "2024-11-03 18:19:10,301 - INFO - logged Train Metrics AUC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: /home/albert/Baikal-ML/experiments/testing/checkpoints/epoch_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 18:19:15,531 - INFO - logged Train Loss FocalLoss\n",
      "2024-11-03 18:19:15,564 - INFO - computed metrics\n",
      "2024-11-03 18:19:15,566 - INFO - logged Train Metrics Accuracy\n",
      "2024-11-03 18:19:15,567 - INFO - logged Train Metrics Precision\n",
      "2024-11-03 18:19:15,568 - INFO - logged Train Metrics TPR\n",
      "2024-11-03 18:19:15,570 - INFO - logged Train Metrics FPR\n",
      "2024-11-03 18:19:15,571 - INFO - logged Train Metrics AUC\n",
      "2024-11-03 18:19:20,996 - INFO - logged Train Loss FocalLoss\n",
      "2024-11-03 18:19:21,054 - INFO - computed metrics\n",
      "2024-11-03 18:19:21,055 - INFO - logged Train Metrics Accuracy\n",
      "2024-11-03 18:19:21,056 - INFO - logged Train Metrics Precision\n",
      "2024-11-03 18:19:21,057 - INFO - logged Train Metrics TPR\n",
      "2024-11-03 18:19:21,059 - INFO - logged Train Metrics FPR\n",
      "2024-11-03 18:19:21,060 - INFO - logged Train Metrics AUC\n",
      "2024-11-03 18:19:26,431 - INFO - logged Train Loss FocalLoss\n",
      "2024-11-03 18:19:26,519 - INFO - computed metrics\n",
      "2024-11-03 18:19:26,521 - INFO - logged Train Metrics Accuracy\n",
      "2024-11-03 18:19:26,522 - INFO - logged Train Metrics Precision\n",
      "2024-11-03 18:19:26,523 - INFO - logged Train Metrics TPR\n",
      "2024-11-03 18:19:26,525 - INFO - logged Train Metrics FPR\n",
      "2024-11-03 18:19:26,526 - INFO - logged Train Metrics AUC\n",
      "2024-11-03 18:19:31,623 - INFO - logged Train Loss FocalLoss\n",
      "2024-11-03 18:19:31,738 - INFO - computed metrics\n",
      "2024-11-03 18:19:31,739 - INFO - logged Train Metrics Accuracy\n",
      "2024-11-03 18:19:31,739 - INFO - logged Train Metrics Precision\n",
      "2024-11-03 18:19:31,740 - INFO - logged Train Metrics TPR\n",
      "2024-11-03 18:19:31,741 - INFO - logged Train Metrics FPR\n",
      "2024-11-03 18:19:31,742 - INFO - logged Train Metrics AUC\n",
      "2024-11-03 18:19:37,144 - INFO - End of Epoch 1. Getting metrics.\n",
      "2024-11-03 18:19:37,270 - INFO - computed metrics\n",
      "2024-11-03 18:19:37,271 - INFO - logged Train Metrics Accuracy\n",
      "2024-11-03 18:19:37,272 - INFO - logged Train Metrics Precision\n",
      "2024-11-03 18:19:37,273 - INFO - logged Train Metrics TPR\n",
      "2024-11-03 18:19:37,274 - INFO - logged Train Metrics FPR\n",
      "2024-11-03 18:19:37,275 - INFO - logged Train Metrics AUC\n",
      "2024-11-03 18:19:37,278 - INFO - Starting evaluation on test dataset\n",
      "2024-11-03 18:19:43,149 - INFO - #0 chunk loaded.\n",
      "2024-11-03 18:20:02,707 - INFO - Shuffled all file paths. Total paths: 10\n",
      "2024-11-03 18:20:02,847 - INFO - computed metrics\n",
      "2024-11-03 18:20:02,848 - INFO - logged Test Metrics Accuracy\n",
      "2024-11-03 18:20:02,849 - INFO - logged Test Metrics Precision\n",
      "2024-11-03 18:20:02,850 - INFO - logged Test Metrics TPR\n",
      "2024-11-03 18:20:02,851 - INFO - logged Test Metrics FPR\n",
      "2024-11-03 18:20:02,852 - INFO - logged Test Metrics AUC\n",
      "2024-11-03 18:20:02,872 - INFO - Saved checkpoint for Epoch 1\n",
      "2024-11-03 18:20:02,873 - INFO - \n",
      "Started Epoch 2/3\n",
      "2024-11-03 18:20:02,932 - INFO - logged Train Loss FocalLoss\n",
      "2024-11-03 18:20:02,940 - INFO - computed metrics\n",
      "2024-11-03 18:20:02,941 - INFO - logged Train Metrics Accuracy\n",
      "2024-11-03 18:20:02,942 - INFO - logged Train Metrics Precision\n",
      "2024-11-03 18:20:02,943 - INFO - logged Train Metrics TPR\n",
      "2024-11-03 18:20:02,944 - INFO - logged Train Metrics FPR\n",
      "2024-11-03 18:20:02,945 - INFO - logged Train Metrics AUC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: /home/albert/Baikal-ML/experiments/testing/checkpoints/epoch_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 18:20:08,272 - INFO - logged Train Loss FocalLoss\n",
      "2024-11-03 18:20:08,309 - INFO - computed metrics\n",
      "2024-11-03 18:20:08,310 - INFO - logged Train Metrics Accuracy\n",
      "2024-11-03 18:20:08,312 - INFO - logged Train Metrics Precision\n",
      "2024-11-03 18:20:08,313 - INFO - logged Train Metrics TPR\n",
      "2024-11-03 18:20:08,315 - INFO - logged Train Metrics FPR\n",
      "2024-11-03 18:20:08,316 - INFO - logged Train Metrics AUC\n",
      "2024-11-03 18:20:13,656 - INFO - logged Train Loss FocalLoss\n",
      "2024-11-03 18:20:13,712 - INFO - computed metrics\n",
      "2024-11-03 18:20:13,713 - INFO - logged Train Metrics Accuracy\n",
      "2024-11-03 18:20:13,714 - INFO - logged Train Metrics Precision\n",
      "2024-11-03 18:20:13,715 - INFO - logged Train Metrics TPR\n",
      "2024-11-03 18:20:13,716 - INFO - logged Train Metrics FPR\n",
      "2024-11-03 18:20:13,717 - INFO - logged Train Metrics AUC\n",
      "2024-11-03 18:20:25,723 - INFO - #1 chunk loaded.\n",
      "2024-11-03 18:20:27,347 - INFO - logged Train Loss FocalLoss\n",
      "2024-11-03 18:20:27,430 - INFO - computed metrics\n",
      "2024-11-03 18:20:27,432 - INFO - logged Train Metrics Accuracy\n",
      "2024-11-03 18:20:27,433 - INFO - logged Train Metrics Precision\n",
      "2024-11-03 18:20:27,435 - INFO - logged Train Metrics TPR\n",
      "2024-11-03 18:20:27,436 - INFO - logged Train Metrics FPR\n",
      "2024-11-03 18:20:27,437 - INFO - logged Train Metrics AUC\n",
      "2024-11-03 18:20:32,436 - INFO - logged Train Loss FocalLoss\n",
      "2024-11-03 18:20:32,550 - INFO - computed metrics\n",
      "2024-11-03 18:20:32,552 - INFO - logged Train Metrics Accuracy\n",
      "2024-11-03 18:20:32,553 - INFO - logged Train Metrics Precision\n",
      "2024-11-03 18:20:32,554 - INFO - logged Train Metrics TPR\n",
      "2024-11-03 18:20:32,556 - INFO - logged Train Metrics FPR\n",
      "2024-11-03 18:20:32,557 - INFO - logged Train Metrics AUC\n",
      "2024-11-03 18:20:37,695 - INFO - End of Epoch 2. Getting metrics.\n",
      "2024-11-03 18:20:37,828 - INFO - computed metrics\n",
      "2024-11-03 18:20:37,829 - INFO - logged Train Metrics Accuracy\n",
      "2024-11-03 18:20:37,831 - INFO - logged Train Metrics Precision\n",
      "2024-11-03 18:20:37,832 - INFO - logged Train Metrics TPR\n",
      "2024-11-03 18:20:37,833 - INFO - logged Train Metrics FPR\n",
      "2024-11-03 18:20:37,835 - INFO - logged Train Metrics AUC\n",
      "2024-11-03 18:20:37,840 - INFO - Starting evaluation on test dataset\n",
      "2024-11-03 18:20:43,322 - INFO - #0 chunk loaded.\n",
      "2024-11-03 18:21:02,851 - INFO - Shuffled all file paths. Total paths: 10\n",
      "2024-11-03 18:21:02,984 - INFO - computed metrics\n",
      "2024-11-03 18:21:02,985 - INFO - logged Test Metrics Accuracy\n",
      "2024-11-03 18:21:02,986 - INFO - logged Test Metrics Precision\n",
      "2024-11-03 18:21:02,987 - INFO - logged Test Metrics TPR\n",
      "2024-11-03 18:21:02,988 - INFO - logged Test Metrics FPR\n",
      "2024-11-03 18:21:02,989 - INFO - logged Test Metrics AUC\n",
      "2024-11-03 18:21:03,007 - INFO - Saved checkpoint for Epoch 2\n",
      "2024-11-03 18:21:03,008 - INFO - Training completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: /home/albert/Baikal-ML/experiments/testing/checkpoints/epoch_3.pt\n"
     ]
    }
   ],
   "source": [
    "fitter.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnetworks.learning.config_manager import save_trainer_cfg\n",
    "save_trainer_cfg(TrainerConfig(), \"./configurations/munusep_basic.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0885, 0.3427],\n",
      "         [0.2025, 0.4914]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0885],\n",
       "         [0.3427]],\n",
       "\n",
       "        [[0.2025],\n",
       "         [0.4914]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "t = torch.rand((1,2,2))\n",
    "print(t)\n",
    "t.permute((1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.zeros((1,5,1))[0,:,0] + torch.ones((5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((5)).view(1, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/albert/Baikal-ML/data/configurations/munusep_all_small')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(\"/home/albert/Baikal-ML/data/configurations/munusep_all_small/test_paths.csv\").parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 10., 10., 10., 10.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.ones((3,5,10)).sum((0,2))/torch.ones((3,1,1)).sum((0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((3,1,1)).sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 25, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.ones((5))/torch.ones((5,1))).view(1, -1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (5) must match the size of tensor b (25) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (5) must match the size of tensor b (25) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "torch.ones((10,5,10)) - (torch.ones((5))/torch.ones((5,1))).view(1, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

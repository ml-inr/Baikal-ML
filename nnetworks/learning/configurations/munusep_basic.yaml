TrainerConfig:

    num_of_epochs: 1

    steps_per_epoch: null

    checkpoint_interval: 1

    checkpoint_path: /home/albert/Baikal-ML/experiments/testing

    log_interval: 100

    optimizer:
        name: Adam
        kwargs:
            lr: 0.0001
            weight_decay: 1.0e-05

    scheduler: null

    loss:
        name: FocalLoss
        kwargs:
            alpha: 1
            gamma: 2

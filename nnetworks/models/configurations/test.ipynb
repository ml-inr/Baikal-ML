{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "PROJECT_PATH = \"/home/albert/Baikal-ML/\" #insert your project path\n",
    "sys.path.append(f\"{PROJECT_PATH}\")\n",
    "from time import time\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnetworks.utils.config_manager import model_from_yaml\n",
    "from nnetworks.models.munusep_resnet import MuNuSepResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = model_from_yaml(MuNuSepResNet, \"./munusep_resnet.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MuNuSepResNet(\n",
       "  (res_blocks): ModuleList(\n",
       "    (0): ResBlock(\n",
       "      (conv_id): MaskedConv1D(\n",
       "        (conv): Conv1d(5, 256, kernel_size=(8,), stride=(1,))\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): LeakyReLU(negative_slope=0.1)\n",
       "        (norm1d): MaskedBatchNorm1D()\n",
       "      )\n",
       "      (conv_cd): MaskedConv1D(\n",
       "        (conv): Conv1d(256, 256, kernel_size=(8,), stride=(2,))\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): LeakyReLU(negative_slope=0.1)\n",
       "        (norm1d): MaskedBatchNorm1D()\n",
       "      )\n",
       "      (conv_skip): MaskedConv1D(\n",
       "        (conv): Conv1d(5, 128, kernel_size=(16,), stride=(2,))\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): LeakyReLU(negative_slope=0.1)\n",
       "        (norm1d): MaskedBatchNorm1D()\n",
       "      )\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (conv_id): MaskedConv1D(\n",
       "        (conv): Conv1d(384, 128, kernel_size=(4,), stride=(1,))\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): LeakyReLU(negative_slope=0.1)\n",
       "        (norm1d): MaskedBatchNorm1D()\n",
       "      )\n",
       "      (conv_cd): MaskedConv1D(\n",
       "        (conv): Conv1d(128, 128, kernel_size=(4,), stride=(2,))\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): LeakyReLU(negative_slope=0.1)\n",
       "        (norm1d): MaskedBatchNorm1D()\n",
       "      )\n",
       "      (conv_skip): MaskedConv1D(\n",
       "        (conv): Conv1d(384, 64, kernel_size=(8,), stride=(2,))\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): LeakyReLU(negative_slope=0.1)\n",
       "        (norm1d): MaskedBatchNorm1D()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooling): GlobalAveragePooling1DMasked()\n",
       "  (dense_layers): ModuleList(\n",
       "    (0): DenseBlock(\n",
       "      (dropout_layer): Dropout(p=0.2, inplace=False)\n",
       "      (dense_layer): Linear(in_features=192, out_features=128, bias=True)\n",
       "      (activation): ReLU()\n",
       "      (norm1d): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): DenseBlock(\n",
       "      (dropout_layer): Dropout(p=0.2, inplace=False)\n",
       "      (dense_layer): Linear(in_features=128, out_features=32, bias=True)\n",
       "      (activation): ReLU()\n",
       "      (norm1d): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): DenseBlock(\n",
       "      (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "      (dense_layer): Linear(in_features=32, out_features=2, bias=True)\n",
       "      (activation): Softmax(dim=1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5271, 0.4729],\n",
       "        [0.2047, 0.7953],\n",
       "        [0.5088, 0.4912],\n",
       "        [0.5086, 0.4914],\n",
       "        [0.5999, 0.4001]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet(torch.rand((5,5,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 1035618\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def count_parameters(model: nn.Module) -> int:\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `model` is an instance of your PyTorch model, such as MuNuSepResNet\n",
    "total_params = count_parameters(resnet)\n",
    "print(f\"Total trainable parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

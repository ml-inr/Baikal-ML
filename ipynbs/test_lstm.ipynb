{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "PROJECT_PATH = \"/home/albert/Baikal-ML/\" #insert your project path\n",
    "sys.path.append(f\"{PROJECT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 10, 1])\n",
      "\n",
      "torch.Size([3, 64])\n",
      "tensor([[ 0.8007, -0.6698,  0.2658, -0.4245, -1.4589, -0.3294,  0.5927, -1.0696,\n",
      "          0.8649, -0.4737, -1.2497,  0.8164, -0.7533,  0.9898,  0.0628,  0.1957,\n",
      "          1.2311,  0.6330,  2.1823,  1.7677,  1.3194,  1.5399, -0.3620, -0.6027,\n",
      "         -1.0231, -2.2173, -1.2308, -0.0849, -0.4654, -0.5583, -0.2949,  0.6827,\n",
      "         -0.3444, -0.6856, -0.3484, -0.5654, -0.4156,  0.9231, -0.2047,  1.8161,\n",
      "         -1.0772, -0.6705, -0.1179,  0.9374, -0.3811,  1.1696, -0.0111, -0.5084,\n",
      "         -0.0367, -0.7520, -0.7550,  1.9995,  1.9023,  0.7913, -0.5466, -1.7673,\n",
      "          0.5004, -0.2736,  1.1735, -0.5016, -1.2207, -1.9663,  1.1416,  0.1189],\n",
      "        [ 0.7934, -0.6662,  0.2671, -0.4218, -1.4534, -0.3160,  0.6020, -1.0786,\n",
      "          0.8640, -0.4732, -1.2472,  0.8289, -0.7506,  0.9863,  0.0669,  0.2017,\n",
      "          1.2211,  0.6344,  2.1872,  1.7647,  1.3138,  1.5336, -0.3602, -0.5902,\n",
      "         -1.0331, -2.1978, -1.2298, -0.0878, -0.4663, -0.5648, -0.2893,  0.6738,\n",
      "         -0.3077, -0.6772, -0.3692, -0.5750, -0.3618,  0.8875, -0.1484,  1.7929,\n",
      "         -1.0923, -0.6667, -0.1160,  0.9118, -0.4136,  1.1736, -0.0146, -0.5413,\n",
      "         -0.0740, -0.7633, -0.7184,  2.0036,  1.9814,  0.7833, -0.5447, -1.7843,\n",
      "          0.4702, -0.2771,  1.1827, -0.4958, -1.2098, -1.9700,  1.1463,  0.0750],\n",
      "        [ 0.7913, -0.6661,  0.2669, -0.4226, -1.4529, -0.3310,  0.5981, -1.0679,\n",
      "          0.8531, -0.4722, -1.2449,  0.8025, -0.7516,  0.9929,  0.0659,  0.1960,\n",
      "          1.2435,  0.6339,  2.1758,  1.7638,  1.3137,  1.5363, -0.3588, -0.6033,\n",
      "         -1.0195, -2.2137, -1.2322, -0.0936, -0.4712, -0.5517, -0.2967,  0.6803,\n",
      "         -0.3220, -0.6883, -0.3560, -0.5558, -0.3902,  0.9139, -0.1615,  1.7955,\n",
      "         -1.0695, -0.6638, -0.1217,  0.9329, -0.4177,  1.1771, -0.0112, -0.5276,\n",
      "         -0.0611, -0.7563, -0.7336,  2.0107,  1.9393,  0.8060, -0.5550, -1.7697,\n",
      "          0.4811, -0.2873,  1.1815, -0.5113, -1.2207, -1.9718,  1.1491,  0.1009]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from nnetworks.layers.config import LstmConfig\n",
    "from nnetworks.layers.recurrent import LstmLayer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "x = torch.rand((3,10,5))\n",
    "mask = torch.ones((3,10,1))\n",
    "mask[:,:,8:] = 0.\n",
    "\n",
    "print(mask.shape)\n",
    "\n",
    "print()\n",
    "\n",
    "layer1 = LstmLayer(LstmConfig(5, 32, return_sequences=True, dropout=0)).to(device)\n",
    "layer2 = LstmLayer(LstmConfig(64, 32, return_sequences=False, dropout=0)).to(device)\n",
    "\n",
    "x, mask = layer1(x.to(device), mask.to(device))\n",
    "x, mask = layer2(x, mask)\n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_lengths = mask.permute((0,2,1)).sum((1,2)).int()\n",
    "x_packed = torch.nn.utils.rnn.pack_padded_sequence(x.permute((0,2,1)), seq_lengths, batch_first=True, enforce_sorted=False)\n",
    "x_unpacked, lens = torch.nn.utils.rnn.pad_packed_sequence(x_packed, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9602, 0.7778, 0.9035, 0.5809, 0.8522],\n",
       "         [0.9988, 0.7547, 0.6862, 0.9939, 0.3699],\n",
       "         [0.1989, 0.0195, 0.1859, 0.2255, 0.0515],\n",
       "         [0.0825, 0.5559, 0.7703, 0.8230, 0.5491],\n",
       "         [0.2470, 0.5166, 0.9346, 0.2490, 0.8540],\n",
       "         [0.9943, 0.3321, 0.4404, 0.0339, 0.7577],\n",
       "         [0.8129, 0.0427, 0.8189, 0.8150, 0.7795],\n",
       "         [0.1300, 0.4416, 0.6594, 0.3438, 0.2170]],\n",
       "\n",
       "        [[0.5098, 0.4356, 0.2161, 0.6960, 0.7278],\n",
       "         [0.9826, 0.3290, 0.8029, 0.5891, 0.0460],\n",
       "         [0.3145, 0.2974, 0.3226, 0.3008, 0.1838],\n",
       "         [0.7262, 0.7762, 0.5743, 0.4647, 0.2241],\n",
       "         [0.3346, 0.7425, 0.2410, 0.4885, 0.9742],\n",
       "         [0.1619, 0.6273, 0.3818, 0.4822, 0.4060],\n",
       "         [0.3273, 0.9638, 0.8088, 0.6849, 0.5540],\n",
       "         [0.9408, 0.5814, 0.1703, 0.5672, 0.3454]],\n",
       "\n",
       "        [[0.0629, 0.0971, 0.6380, 0.0012, 0.1572],\n",
       "         [0.7093, 0.2241, 0.9507, 0.7804, 0.0749],\n",
       "         [0.6821, 0.0795, 0.1010, 0.5428, 0.0317],\n",
       "         [0.6596, 0.2987, 0.0564, 0.0131, 0.7908],\n",
       "         [0.2106, 0.5882, 0.0271, 0.7978, 0.2100],\n",
       "         [0.1795, 0.5632, 0.1217, 0.6934, 0.2104],\n",
       "         [0.4471, 0.9881, 0.9912, 0.3358, 0.7839],\n",
       "         [0.9904, 0.2487, 0.6050, 0.0853, 0.7630]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_unpacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8, 8, 8])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = torch.nn.LSTM(\n",
    "            input_size=5,\n",
    "            hidden_size=32,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            dropout=0,\n",
    "            bidirectional=True # merge mode is concat by torch realization\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_out, _ = lstm(x_packed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[-8.9833e-02,  1.4103e-02,  6.9557e-02,  ..., -3.7554e-02,\n",
       "         -8.4614e-05,  1.8708e-01],\n",
       "        [-6.1768e-02,  3.2840e-02,  5.3113e-02,  ..., -3.4246e-02,\n",
       "          1.7363e-02,  1.6012e-01],\n",
       "        [-6.7546e-02, -7.2765e-03,  8.2122e-02,  ..., -3.9059e-02,\n",
       "          1.6766e-02,  1.6971e-01],\n",
       "        ...,\n",
       "        [-1.7902e-01,  1.1500e-02,  1.3763e-01,  ...,  1.2252e-02,\n",
       "         -1.2653e-02,  6.0942e-02],\n",
       "        [-1.5605e-01,  3.4304e-02,  1.2970e-01,  ..., -1.7229e-02,\n",
       "          2.9652e-02,  6.5387e-02],\n",
       "        [-1.6116e-01,  1.0137e-02,  1.4287e-01,  ..., -2.4414e-02,\n",
       "          3.8958e-02,  9.5758e-02]], grad_fn=<CatBackward0>), batch_sizes=tensor([3, 3, 3, 3, 3, 3, 3, 3]), sorted_indices=tensor([0, 1, 2]), unsorted_indices=tensor([0, 1, 2]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

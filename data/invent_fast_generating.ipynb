{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pack_sequence, unpack_sequence, pad_sequence\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "from root_manager.chunk_generator import ChunkGenerator\n",
    "from root_manager.settings import ChunkGeneratorConfig, ProcessorConfig, FilterParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mu = \"/net/62/home3/ivkhar/Baikal/data/initial_data/MC_2020/muatm/root/all/\"\n",
    "path_nuatm = \"/net/62/home3/ivkhar/Baikal/data/initial_data/MC_2020/nuatm/root/all/\"\n",
    "path_nu2 = \"/net/62/home3/ivkhar/Baikal/data/initial_data/MC_2020/nue2_100pev/root/all/\"\n",
    "def explore_paths(p: str, start: int, stop: int):\n",
    "    files = sorted(os.listdir(p))[start:stop]\n",
    "    return [f\"{p}{file}\" for file in files]\n",
    "mu_paths = explore_paths(path_mu, 0, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_cfg = ProcessorConfig(\n",
    "    center_times= True, \n",
    "    calc_tres = False, \n",
    "    filter_cfg = FilterParams(\n",
    "        only_signal = False,\n",
    "        min_hits = 0,\n",
    "        min_strings = 0,\n",
    "        min_Q = 0,\n",
    "        t_threshold = 100000\n",
    "    )\n",
    ")\n",
    "chunk_generator_cfg=ChunkGeneratorConfig(\n",
    "            chunk_size = 25,\n",
    "            processor_params = proc_cfg,\n",
    "            fields = ['PulsesAmpl', 'PulsesTime', 'Xrel', 'Yrel', 'Zrel', 'num_signal_hits', 'num_signal_strings', 'nu_induced'],\n",
    "            shuffle_paths = False\n",
    "        )\n",
    "\n",
    "gen = ChunkGenerator(mu_paths, chunk_generator_cfg).get_chunks()\n",
    "df = next(gen)\n",
    "df_features = df[['PulsesAmpl', 'PulsesTime', 'Xrel', 'Yrel', 'Zrel']]\n",
    "\n",
    "data = df_features.to_numpy()[:,:5]\n",
    "for i in range(len(data)):\n",
    "    data[i] = data[i, :]\n",
    "    for j in range(len(data[i])):\n",
    "        data[i, j] = data[i, j].round(3).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of numpy arrays to torch tensors\n",
    "torch_tensors = list(map(torch.from_numpy, map(lambda x: np.stack(x, axis=-1), list(df_features.to_numpy()))))\n",
    "#torch_tensors = pad_sequence(torch_tensors, batch_first=True, padding_value=float('nan'))\n",
    "# data_seq, _, sorted_idxs, idxs = pack_sequence(torch_tensors, enforce_sorted=False)\n",
    "# t = pack_sequence(torch_tensors, enforce_sorted=False)\n",
    "# unpack_sequence(t)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for arr in map(lambda x: np.stack(x, axis=-1), list(df_features.to_numpy())):\n",
    "    torch.from_numpy(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32680, 148, 5])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_tensors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpack_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_features\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPulsesAmpl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menforce_sorted\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Baikal-ML/venv/lib/python3.10/site-packages/torch/nn/utils/rnn.py:565\u001b[0m, in \u001b[0;36mpack_sequence\u001b[0;34m(sequences, enforce_sorted)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpack_sequence\u001b[39m(\n\u001b[1;32m    533\u001b[0m     sequences: List[Tensor],\n\u001b[1;32m    534\u001b[0m     enforce_sorted: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    535\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PackedSequence:\n\u001b[1;32m    536\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Packs a list of variable length Tensors.\u001b[39;00m\n\u001b[1;32m    537\u001b[0m \n\u001b[1;32m    538\u001b[0m \u001b[38;5;124;03m    Consecutive call of the next functions: ``pad_sequence``, ``pack_padded_sequence``.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;124;03m        a :class:`PackedSequence` object\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m     lengths \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor([v\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m sequences])\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pack_padded_sequence(\n\u001b[1;32m    567\u001b[0m         pad_sequence(sequences), lengths, enforce_sorted\u001b[38;5;241m=\u001b[39menforce_sorted\n\u001b[1;32m    568\u001b[0m     )\n",
      "File \u001b[0;32m~/Baikal-ML/venv/lib/python3.10/site-packages/torch/nn/utils/rnn.py:565\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpack_sequence\u001b[39m(\n\u001b[1;32m    533\u001b[0m     sequences: List[Tensor],\n\u001b[1;32m    534\u001b[0m     enforce_sorted: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    535\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PackedSequence:\n\u001b[1;32m    536\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Packs a list of variable length Tensors.\u001b[39;00m\n\u001b[1;32m    537\u001b[0m \n\u001b[1;32m    538\u001b[0m \u001b[38;5;124;03m    Consecutive call of the next functions: ``pad_sequence``, ``pack_padded_sequence``.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;124;03m        a :class:`PackedSequence` object\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m     lengths \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor([\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m sequences])\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pack_padded_sequence(\n\u001b[1;32m    567\u001b[0m         pad_sequence(sequences), lengths, enforce_sorted\u001b[38;5;241m=\u001b[39menforce_sorted\n\u001b[1;32m    568\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "pack_sequence(df_features['PulsesAmpl'].to_list(), enforce_sorted = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (32_680,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>data</th></tr><tr><td>struct[5]</td></tr></thead><tbody><tr><td>{[1.910719, 0.680661, … 0.79696],[-2538.06543, -2533.398438, … 2374.409668],[-58.110868, -40.877882, … -31.008856],[-4.861609, 41.557367, … -49.470633],[247.525992, 7.690028, … 7.319012]}</td></tr><tr><td>{[0.630403, 0.819006, … 1.506786],[-2728.459961, -2557.720947, … 2251.506592],[53.961874, -40.992133, … -0.395121],[-19.536512, 42.604509, … -1.683516],[247.731508, 127.881517, … -7.559459]}</td></tr><tr><td>{[1.24319, 0.45773, … 2.384422],[-2401.945068, -2352.771484, … 2511.410889],[-53.664543, 60.158501, … -8.936485],[27.840374, -2.030605, … 57.560368],[203.033434, 202.674502, … 218.029498]}</td></tr><tr><td>{[0.330916, 0.959203, … 1.128354],[-2343.806396, -2207.74707, … 2409.185547],[17.954746, 62.309757, … -62.23724],[-55.696244, -15.339253, … -12.04324],[-83.579933, 262.120064, … 7.328074]}</td></tr><tr><td>{[1.19767, 1.896235, … 1.27869],[-2306.198486, -2256.801758, … 2628.382324],[2.177528, 34.699516, … -55.225517],[-0.764629, -46.808651, … -23.255611],[-263.652494, 217.675479, … 233.055514]}</td></tr><tr><td>&hellip;</td></tr><tr><td>{[1.045604, 0.780759, … 0.657507],[-2200.046875, -2197.669922, … 2780.611328],[-33.253271, -41.625219, … -58.665289],[-49.427752, 44.301244, … -4.282756],[-233.135579, -97.345578, … 172.90942]}</td></tr><tr><td>{[0.343402, 0.499559, … 0.479027],[-2306.005859, -2245.419434, … 2608.529785],[-40.992133, -40.992133, … 4.32488],[42.604509, 42.604509, … 58.976503],[-67.361471, 127.881517, … 172.776476]}</td></tr><tr><td>{[0.189371, 1.033087, … 1.485312],[-2215.638672, -2204.812988, … 2600.888916],[3.311741, -62.23724, … 62.309757],[-0.165249, -12.04324, … -15.339253],[132.839088, -203.086922, … 111.798073]}</td></tr><tr><td>{[0.909729, 1.219074, … 1.32461],[-2636.730713, -2597.872803, … 2249.924316],[3.311741, 48.696751, … 17.954746],[-0.165249, 34.162761, … -55.696244],[162.74604, -158.070931, … 6.748074]}</td></tr><tr><td>{[1.05532, 1.05321, … 0.94438],[-2620.739746, -2526.647217, … 2229.183838],[17.954746, -62.23724, … -42.039257],[-55.696244, -12.04324, … 38.46075],[187.04409, 157.431038, … 247.100059]}</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (32_680,)\n",
       "Series: 'data' [struct[5]]\n",
       "[\n",
       "\t{[1.910719, 0.680661, … 0.79696],[-2538.06543, -2533.398438, … 2374.409668],[-58.110868, -40.877882, … -31.008856],[-4.861609, 41.557367, … -49.470633],[247.525992, 7.690028, … 7.319012]}\n",
       "\t{[0.630403, 0.819006, … 1.506786],[-2728.459961, -2557.720947, … 2251.506592],[53.961874, -40.992133, … -0.395121],[-19.536512, 42.604509, … -1.683516],[247.731508, 127.881517, … -7.559459]}\n",
       "\t{[1.24319, 0.45773, … 2.384422],[-2401.945068, -2352.771484, … 2511.410889],[-53.664543, 60.158501, … -8.936485],[27.840374, -2.030605, … 57.560368],[203.033434, 202.674502, … 218.029498]}\n",
       "\t{[0.330916, 0.959203, … 1.128354],[-2343.806396, -2207.74707, … 2409.185547],[17.954746, 62.309757, … -62.23724],[-55.696244, -15.339253, … -12.04324],[-83.579933, 262.120064, … 7.328074]}\n",
       "\t{[1.19767, 1.896235, … 1.27869],[-2306.198486, -2256.801758, … 2628.382324],[2.177528, 34.699516, … -55.225517],[-0.764629, -46.808651, … -23.255611],[-263.652494, 217.675479, … 233.055514]}\n",
       "\t…\n",
       "\t{[1.045604, 0.780759, … 0.657507],[-2200.046875, -2197.669922, … 2780.611328],[-33.253271, -41.625219, … -58.665289],[-49.427752, 44.301244, … -4.282756],[-233.135579, -97.345578, … 172.90942]}\n",
       "\t{[0.343402, 0.499559, … 0.479027],[-2306.005859, -2245.419434, … 2608.529785],[-40.992133, -40.992133, … 4.32488],[42.604509, 42.604509, … 58.976503],[-67.361471, 127.881517, … 172.776476]}\n",
       "\t{[0.189371, 1.033087, … 1.485312],[-2215.638672, -2204.812988, … 2600.888916],[3.311741, -62.23724, … 62.309757],[-0.165249, -12.04324, … -15.339253],[132.839088, -203.086922, … 111.798073]}\n",
       "\t{[0.909729, 1.219074, … 1.32461],[-2636.730713, -2597.872803, … 2249.924316],[3.311741, 48.696751, … 17.954746],[-0.165249, 34.162761, … -55.696244],[162.74604, -158.070931, … 6.748074]}\n",
       "\t{[1.05532, 1.05321, … 0.94438],[-2620.739746, -2526.647217, … 2229.183838],[17.954746, -62.23724, … -42.039257],[-55.696244, -12.04324, … 38.46075],[187.04409, 157.431038, … 247.100059]}\n",
       "]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pack_sequence\n",
    "\n",
    "def list_to_packed_sequence(array_list):\n",
    "    # Convert each numpy array in the list to a torch tensor\n",
    "    tensor_list = [torch.tensor(arr, dtype=torch.float32) for arr in array_list]\n",
    "    \n",
    "    # Pack the sequence directly, this will handle variable lengths efficiently\n",
    "    packed_sequence = pack_sequence(tensor_list, enforce_sorted=False)\n",
    "    \n",
    "    return packed_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[43mlist_to_packed_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m, in \u001b[0;36mlist_to_packed_sequence\u001b[0;34m(array_list)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlist_to_packed_sequence\u001b[39m(array_list):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Convert each numpy array in the list to a torch tensor\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     tensor_list \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mtensor(arr, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m array_list]\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Pack the sequence directly, this will handle variable lengths efficiently\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     packed_sequence \u001b[38;5;241m=\u001b[39m pack_sequence(tensor_list, enforce_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlist_to_packed_sequence\u001b[39m(array_list):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Convert each numpy array in the list to a torch tensor\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     tensor_list \u001b[38;5;241m=\u001b[39m [\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m array_list]\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Pack the sequence directly, this will handle variable lengths efficiently\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     packed_sequence \u001b[38;5;241m=\u001b[39m pack_sequence(tensor_list, enforce_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool."
     ]
    }
   ],
   "source": [
    "t = list_to_packed_sequence(list(df_features.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "np.concatenate(data, axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32680, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
